# Interpreting Sign Language using Neural Networks

### Question/need:
* What is the framing question of your analysis, or the purpose of the model/system you plan to build?

[American Sign Language/ASL](https://www.nidcd.nih.gov/health/american-sign-language) is a primary means of communication for deaf, hard of hearing and hearing nonverbal children who are nonverbal due to conditions such as down syndrome, autism, cerebral palsy, trauma, and brain disorders or speech disorders. Deaf students are considered as a linguistic minority and interpreting the language with less effort. 

Majority of general population is unable to communicate in sign language. The aim of this project is to interprete these signs into English alphabets. 

* Who benefits from exploring this question or building this model/system?

Communication is a key factor for a healthy social life and making applications that can easily translate ASL can help people in need feel included. 

### Data Description:

* What dataset(s) do you plan to use, and how will you obtain the data?

Data is downloaded from [Kaggle](https://www.kaggle.com/datamunge/sign-language-mnist) and consists of image information about each alphabet in sign language. Train and test files are included seperately. 





